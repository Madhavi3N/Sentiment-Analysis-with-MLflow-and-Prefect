{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe09726",
   "metadata": {},
   "source": [
    "##  * * * * * * * * *  - : `Prefect Workflow` : -  * * * * * * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a1546",
   "metadata": {},
   "source": [
    "### * `Task` :-  Build a Prefect Workflow and Auto Schedule it. Show the Prefect Dashboard with relevant outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139db304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\91994\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### Load the required libraries\n",
    "%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d92f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb32706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    X = data[inputs]\n",
    "    y = data[output]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86191e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f8d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Pre-processing the data\n",
    "    \"\"\"\n",
    "    def clean_text(data):\n",
    "        \"\"\"\n",
    "        cleaning the data.\n",
    "        \"\"\"\n",
    "        tqdm.pandas()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "        # Removing special characters and digits\n",
    "        sentence = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", data)\n",
    "    \n",
    "        # change sentence to lower case\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        # tokenize into words\n",
    "        tokens = sentence.split()\n",
    "    \n",
    "        # remove stop words                \n",
    "        clean_tokens = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "    \n",
    "        clean_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    \n",
    "        sentence =  \" \".join(clean_tokens)\n",
    "    \n",
    "        return sentence\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        X_train[col] = X_train[col].apply(lambda doc: clean_text(doc))\n",
    "    for col in X_test.columns:\n",
    "        X_test[col] = X_test[col].apply(lambda doc: clean_text(doc))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d97328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    vectorizing the data.\n",
    "    \"\"\"\n",
    "    vector = CountVectorizer()\n",
    "    X_train_vec = vector.fit_transform(X_train)\n",
    "    X_test_vec = vector.transform(X_test)\n",
    "    return X_train_vec, X_test_vec, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e860ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_vec, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = DecisionTreeClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1876efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train_vec, y_train, X_test_vec, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train_vec)\n",
    "    y_test_pred = model.predict(X_test_vec)\n",
    "\n",
    "    train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01070695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow(data_path):\n",
    "    DATA_PATH = data_path\n",
    "    INPUTS = ['Review text']\n",
    "    OUTPUT = 'Review Sentiment'\n",
    "    HYPERPARAMETERS = {'max_features' : 1000, 'max_depth': 10}\n",
    "    \n",
    "    # Load data\n",
    "    reviews = load_data(DATA_PATH)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(reviews, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "    \n",
    "    #preprocessing the data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # vectorizing to data\n",
    "    X_train_vec, X_test_vec, y_train, y_test = vectorizing_data(X_train['Review text'], X_test['Review text'], y_train, y_test)\n",
    "    \n",
    "    # Build a model\n",
    "    model = train_model(X_train_vec, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0298ffba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9263281479307308\n",
      "Test Score: 0.8996478873239436\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow(data_path=\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aad2b06",
   "metadata": {},
   "source": [
    "### * * * * `Building a Prefect Workflow` * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ffa57",
   "metadata": {},
   "source": [
    "##### Step 1 - Import Prefect modules\n",
    "\n",
    "##### Step 2 - Define Prefect Tasks\n",
    "\n",
    "##### Step 3 - Define Prefect Flow\n",
    "\n",
    "##### Step 5 - Run Prefect Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7539b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e416294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "@task\n",
    "def split_inputs_output(data, inputs, output):\n",
    "    \"\"\"\n",
    "    Split features and target variables.\n",
    "    \"\"\"\n",
    "    X = data[inputs]\n",
    "    y = data[output]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "@task\n",
    "def split_train_test(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "\n",
    "@task\n",
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Pre-processing the data\n",
    "    \"\"\"\n",
    "    def clean_text(data):\n",
    "        \"\"\"\n",
    "        cleaning the data.\n",
    "        \"\"\"\n",
    "        tqdm.pandas()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "        # Removing special characters and digits\n",
    "        sentence = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", data)\n",
    "    \n",
    "        # change sentence to lower case\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        # tokenize into words\n",
    "        tokens = sentence.split()\n",
    "    \n",
    "        # remove stop words                \n",
    "        clean_tokens = [t for t in tokens if not t in stopwords.words(\"english\")]\n",
    "    \n",
    "        clean_tokens = [lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "    \n",
    "        sentence =  \" \".join(clean_tokens)\n",
    "    \n",
    "        return sentence\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        X_train[col] = X_train[col].apply(lambda doc: clean_text(doc))\n",
    "    for col in X_test.columns:\n",
    "        X_test[col] = X_test[col].apply(lambda doc: clean_text(doc))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "@task\n",
    "def vectorizing_data(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    vectorizing the data.\n",
    "    \"\"\"\n",
    "    vector = CountVectorizer()\n",
    "    X_train_vec = vector.fit_transform(X_train)\n",
    "    X_test_vec = vector.transform(X_test)\n",
    "    return X_train_vec, X_test_vec, y_train, y_test\n",
    "\n",
    "\n",
    "@task\n",
    "def train_model(X_train_vec, y_train, hyperparameters):\n",
    "    \"\"\"\n",
    "    Training the machine learning model.\n",
    "    \"\"\"\n",
    "    clf = DecisionTreeClassifier(**hyperparameters)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "@task\n",
    "def evaluate_model(model, X_train_vec, y_train, X_test_vec, y_test):\n",
    "    \"\"\"\n",
    "    Evaluating the model.\n",
    "    \"\"\"\n",
    "    y_train_pred = model.predict(X_train_vec)\n",
    "    y_test_pred = model.predict(X_test_vec)\n",
    "\n",
    "    train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "    test_score = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow\n",
    "\n",
    "@flow(name=\"Decision Tree Training Flow\")\n",
    "def workflow():\n",
    "    DATA_PATH = \"data/data.csv\"\n",
    "    INPUTS = ['Review text']\n",
    "    OUTPUT = 'Review Sentiment'\n",
    "    HYPERPARAMETERS = {'max_features' : 1000, 'max_depth': 10}\n",
    "    \n",
    "    # Load data\n",
    "    reviews = load_data(DATA_PATH)\n",
    "\n",
    "    # Identify Inputs and Output\n",
    "    X, y = split_inputs_output(reviews, INPUTS, OUTPUT)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "    \n",
    "    #preprocessing the data\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # vectorizing to data\n",
    "    X_train_vec, X_test_vec, y_train, y_test = vectorizing_data(X_train['Review text'], X_test['Review text'], y_train, y_test)\n",
    "    \n",
    "    # Build a model\n",
    "    model = train_model(X_train_vec, y_train, HYPERPARAMETERS)\n",
    "    \n",
    "    # Evaluation\n",
    "    train_score, test_score = evaluate_model(model, X_train_vec, y_train, X_test_vec, y_test)\n",
    "    \n",
    "    print(\"Train Score:\", train_score)\n",
    "    print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96a486a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:55.348 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Decision Tree Training Flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:55.348 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'heavy-yak'\u001b[0m for flow\u001b[1;35m 'Decision Tree Training Flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:55.680 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'load_data-0' for task 'load_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:55.680 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'load_data-0' for task 'load_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:55.696 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'load_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:55.696 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'load_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.071 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.071 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.167 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.167 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'split_inputs_output-0' for task 'split_inputs_output'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.167 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'split_inputs_output-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.167 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'split_inputs_output-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.447 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_inputs_output-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.447 | \u001b[36mINFO\u001b[0m    | Task run 'split_inputs_output-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.564 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'split_train_test-0' for task 'split_train_test'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.564 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'split_train_test-0' for task 'split_train_test'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.581 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'split_train_test-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.581 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'split_train_test-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.874 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'split_train_test-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.874 | \u001b[36mINFO\u001b[0m    | Task run 'split_train_test-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.978 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'preprocess_data-0' for task 'preprocess_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.978 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'preprocess_data-0' for task 'preprocess_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:06:56.978 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'preprocess_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:06:56.978 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'preprocess_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:42.458 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'preprocess_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:42.458 | \u001b[36mINFO\u001b[0m    | Task run 'preprocess_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:42.588 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'vectorizing_data-0' for task 'vectorizing_data'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:42.588 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'vectorizing_data-0' for task 'vectorizing_data'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:42.596 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'vectorizing_data-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:42.596 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'vectorizing_data-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:42.930 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'vectorizing_data-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:42.930 | \u001b[36mINFO\u001b[0m    | Task run 'vectorizing_data-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.020 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'train_model-0' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.020 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'train_model-0' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.020 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'train_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.020 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'train_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.271 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.271 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.350 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Created task run 'evaluate_model-0' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.350 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Created task run 'evaluate_model-0' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.350 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Executing 'evaluate_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.350 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Executing 'evaluate_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.626 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.626 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9241267977692985\n",
      "Test Score: 0.9008215962441315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">16:07:43.734 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'heavy-yak'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "16:07:43.734 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'heavy-yak'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `list`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DecisionTreeClassifier`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aef4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
